import { NextRequest, NextResponse } from "next/server";
import OpenAI from "openai";

// Import migrated AI advisor system
import {
  defaultProvider,
  getLLMConfig,
  mcpConfig,
  memoryEnabled,
  openaiConfig,
} from "@/lib/ai-advisor/config/index";
import { AIAdvisorOrchestratorService } from "@/lib/ai-advisor/services/ai-advisor-orchestrator.service";
import { MemoryManagerFactory } from "@/lib/ai-advisor/services/memory-manager.factory";
import { RequestBody } from "@/lib/ai-advisor/types/index";
import {
  handleMCPError,
  validateInitialRequestBody,
  validateRequestBody,
} from "@/lib/ai-advisor/utils/validation";
import { createClient } from "@/lib/supabase/server";
import { AsyncMemoryManager } from "@/lib/ai-advisor/memory-manager";
import { UserProfile } from "@/lib/types/user.types";

// Initialize OpenAI client
const openaiClient = new OpenAI({
  apiKey: openaiConfig.apiKey,
});

// Initialize AsyncMemoryManager using factory (with safe fallback)
let memoryManager: AsyncMemoryManager | null = null;
if (memoryEnabled) {
  try {
    memoryManager = MemoryManagerFactory.createFromEnv();
    console.log("‚úÖ Memory manager initialized successfully");
  } catch (error) {
    console.warn(
      "‚ö†Ô∏è Memory manager initialization failed, continuing without memory:",
      error
    );
    memoryManager = null;
  }
} else {
  console.log("‚ÑπÔ∏è Memory is disabled via configuration");
}

// Initialize orchestrator service

export async function POST(request: NextRequest) {
  try {
    const requestBody = await request.json();

    console.log("üìã Raw request body received:", {
      bodyType: typeof requestBody,
      keys:
        requestBody && typeof requestBody === "object"
          ? Object.keys(requestBody)
          : "none",
      hasMessage: !!requestBody?.message,
      messageLength: requestBody?.message ? requestBody.message.length : 0,
      hasConversationHistory: !!requestBody?.conversationHistory,
      historyLength: Array.isArray(requestBody?.conversationHistory)
        ? requestBody.conversationHistory.length
        : 0,
      hasUserContext: !!requestBody?.userContext,
      provider: requestBody?.provider || "not specified",
    });

    const initialValidation = validateInitialRequestBody(requestBody);
    if (!initialValidation.isValid) {
      console.error(
        "‚ùå Initial request validation failed:",
        initialValidation.error
      );
      return NextResponse.json(
        { error: initialValidation.error },
        { status: 400 }
      );
    }

    const supabase = await createClient();

    const {
      data: { user },
      error: authError,
    } = await supabase.auth.getUser();

    if (authError || !user) {
      console.error(
        "‚ùå Authentication failed:",
        authError?.message || "No user found"
      );
      return NextResponse.json(
        { error: "Authentication required" },
        { status: 401 }
      );
    }

    const userProfile = await supabase
      .from("users")
      .select("*")
      .eq("user_id", user.id)
      .single();

    if (!userProfile.data) {
      console.error("‚ùå User profile not found");
      return NextResponse.json(
        { error: "User profile not found" },
        { status: 404 }
      );
    }

    // Prepare request with user ID
    console.log("üìù Preparing AI advisor request...");
    const aiAdvisorRequest: RequestBody = {
      ...requestBody,
      user_id: user.id,
    };

    // Validate complete request body (after authentication)
    console.log("üîç Starting complete request validation...");
    const completeValidation = validateRequestBody(aiAdvisorRequest);
    if (!completeValidation.isValid) {
      console.error(
        "‚ùå Complete request validation failed:",
        completeValidation.error
      );
      return NextResponse.json(
        { error: completeValidation.error },
        { status: 400 }
      );
    }
    console.log("‚úÖ Complete request validation passed");

    console.log("üìä Final AI advisor request:", {
      hasMessage: !!aiAdvisorRequest.message,
      messageLength: aiAdvisorRequest.message?.length || 0,
      hasUserId: !!aiAdvisorRequest.user_id,
      hasConversationHistory: !!aiAdvisorRequest.conversationHistory,
      historyLength: Array.isArray(aiAdvisorRequest.conversationHistory)
        ? aiAdvisorRequest.conversationHistory.length
        : 0,
      hasUserContext: !!aiAdvisorRequest.userContext,
      provider: aiAdvisorRequest.provider || "default",
    });

    // Determine which LLM provider to use
    const selectedProvider = requestBody.provider || defaultProvider;
    const llmConfig = getLLMConfig(selectedProvider);

    console.log("ü§ñ LLM Configuration:", {
      provider: llmConfig.provider,
      model: llmConfig.model,
      temperature: llmConfig.temperature,
      hasApiKey: !!llmConfig.apiKey,
    });

    // Set up Server-Sent Events headers
    console.log("üì° Setting up SSE headers...");
    const headers = new Headers({
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
      "Access-Control-Allow-Origin": "*",
      "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
      "Access-Control-Allow-Headers": "Content-Type, Authorization",
    });

    // Create a readable stream
    console.log("üåä Creating readable stream...");
    let readable: ReadableStream | null = null;
    const orchestratorService = new AIAdvisorOrchestratorService(
      userProfile.data as UserProfile,
      openaiClient,
      memoryManager,
      mcpConfig
    );
    try {
      readable = await orchestratorService.processRequest(
        aiAdvisorRequest,
        llmConfig
      );
      console.log("‚úÖ Orchestrator completed successfully");
    } catch (error) {
      console.error("‚ùå Streaming error:", error);
      handleMCPError(error, "streaming");
    }

    console.log("üöÄ Returning stream response");
    return new Response(readable, { headers });
  } catch (error) {
    console.error("‚ùå Function error:", error);
    console.error(
      "‚ùå Error stack:",
      error instanceof Error ? error.stack : "No stack available"
    );
    handleMCPError(error, "main function");

    const errorDetails = {
      error: error instanceof Error ? error.message : "Unknown error",
      context: "ai_advisor_stream_function",
      timestamp: new Date().toISOString(),
      errorType: error instanceof Error ? error.constructor.name : typeof error,
    };

    console.error("‚ùå Returning error response:", errorDetails);

    return NextResponse.json(errorDetails, {
      status: 500,
    });
  }
}

export async function OPTIONS() {
  console.log("‚öôÔ∏è OPTIONS request received");
  return new Response(null, {
    status: 200,
    headers: {
      "Access-Control-Allow-Origin": "*",
      "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
      "Access-Control-Allow-Headers": "Content-Type, Authorization",
    },
  });
}
